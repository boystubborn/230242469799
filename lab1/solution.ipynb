{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taJlOyc1Bm9y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nLab one - Understanding and Preprocessing Data\\nCourse: Data Mining and Analytics - COU08104\\nAuthor: danilph\\n\\n'"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Lab one - Understanding and Preprocessing Data\n",
        "Course: Data Mining and Analytics - COU08104\n",
        "Author: danilph\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "LAB ONE \n",
        "BENG22COE-2\n",
        "GROUP  MEMBERS\n",
        "STEVEN DAUD NDYAMUKAMA     230242469799\n",
        "JOHN PAUL                  230242423127\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "F09MrMdXubMh"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "library import\n",
        "'''\n",
        "\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.spatial import distance\n",
        "from scipy.stats import mode\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "xNtwJpddvBss"
      },
      "outputs": [],
      "source": [
        "titanic_data=pd.read_csv(\"titanic.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omXFYP3a5WPE"
      },
      "source": [
        "**SECTION** A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "gcJw7wmkvdPR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nTODO:\\n1. Display/print out data shape & at least 5 first rows.\\n2. Print out attribute type:\\n        -Nominal,\\n        -Binary,\\n        -Ordinal,\\n        -Numeric,Discrete and Ratio-scaled\\n'"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "TODO:\n",
        "1. Display/print out data shape & at least 5 first rows.\n",
        "2. Print out attribute type:\n",
        "        -Nominal,\n",
        "        -Binary,\n",
        "        -Ordinal,\n",
        "        -Numeric,Discrete and Ratio-scaled\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "1pZvqPZlBrB-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Shape:\n",
            "(1309, 14)\n",
            "\n",
            "First 5 Rows of the Dataset:\n",
            "   pclass  survived                                             name     sex  \\\n",
            "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
            "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
            "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
            "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
            "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
            "\n",
            "     age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
            "0  29.00      0      0   24160  211.3375       B5        S    2    NaN   \n",
            "1   0.92      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
            "2   2.00      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
            "3  30.00      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
            "4  25.00      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
            "\n",
            "                         home.dest  \n",
            "0                     St Louis, MO  \n",
            "1  Montreal, PQ / Chesterville, ON  \n",
            "2  Montreal, PQ / Chesterville, ON  \n",
            "3  Montreal, PQ / Chesterville, ON  \n",
            "4  Montreal, PQ / Chesterville, ON  \n",
            "\n",
            "2 Attribute types:\n",
            "\n",
            "Nominal:\n",
            "  - name\n",
            "  - sex\n",
            "  - ticket\n",
            "  - cabin\n",
            "  - embarked\n",
            "\n",
            "Binary:\n",
            "  - survived\n",
            "\n",
            "Ordinal:\n",
            "  - pclass\n",
            "\n",
            "Numeric (Discrete):\n",
            "  - sibsp\n",
            "  - parch\n",
            "\n",
            "Numeric (Ratio-scaled / Continuous):\n",
            "  - age\n",
            "  - fare\n"
          ]
        }
      ],
      "source": [
        "# 1. Displaying shape of the dataset\n",
        "print(\"Dataset Shape:\")\n",
        "print(titanic_data.shape)\n",
        "\n",
        "# Displaying first 5 rows\n",
        "print(\"\\nFirst 5 Rows of the Dataset:\")\n",
        "print(titanic_data.head())\n",
        "\n",
        "print(\"\\n2 Attribute types:\")\n",
        "\n",
        "attribute_types = {\n",
        "     \"Nominal\": [\n",
        "        \"name\", \"sex\", \"ticket\", \"cabin\", \"embarked\"\n",
        "    ],\n",
        "\n",
        "    \"Binary\": [\n",
        "        \"survived\"\n",
        "    ],\n",
        " \"Ordinal\": [\n",
        "        \"pclass\"\n",
        "    ],\n",
        "    \"Numeric (Discrete)\": [\n",
        "        \"sibsp\", \"parch\"\n",
        "    ],\n",
        "\n",
        " \"Numeric (Ratio-scaled / Continuous)\": [\n",
        "        \"age\", \"fare\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "for attribute_type, columns in attribute_types.items():\n",
        "    print(f\"\\n{attribute_type}:\")\n",
        "    for column in columns:\n",
        "        if column in titanic_data.columns:\n",
        "            print(f\"  - {column}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixn-WD5BzgS4",
        "outputId": "fce734a3-67f0-45eb-d2f6-d40f4bab839e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "2.1 Measures of Central Tendency (Using python library Pandas):\n",
            "\n",
            "Numeric Attributes Statistics:\n",
            "\n",
            "age:\n",
            "  Mean:   29.88\n",
            "  Median: 28.00\n",
            "  Mode:   24.0\n",
            "\n",
            "fare:\n",
            "  Mean:   33.30\n",
            "  Median: 14.45\n",
            "  Mode:   8.05\n",
            "\n",
            "sibsp:\n",
            "  Mean:   0.50\n",
            "  Median: 0.00\n",
            "  Mode:   0\n",
            "\n",
            "parch:\n",
            "  Mean:   0.39\n",
            "  Median: 0.00\n",
            "  Mode:   0\n",
            "\n",
            "\n",
            "Nominal Attributes - Mode (Using Pandas):\n",
            "sex: male\n",
            "embarked: S\n",
            "\n",
            "2.2 Measures of Dispersion :\n",
            "\n",
            "age:\n",
            "  Range:             79.83\n",
            "  Variance:          207.75\n",
            "  Standard Dev:      14.41\n",
            "  Interquartile Rng: 18.00\n",
            "\n",
            "fare:\n",
            "  Range:             512.33\n",
            "  Variance:          2678.96\n",
            "  Standard Dev:      51.76\n",
            "  Interquartile Rng: 23.38\n",
            "\n",
            "2.3   Identifying Outliers using IQR Method :\n",
            "\n",
            "age:\n",
            "  Quat1: 21.00, Quat3: 39.00, IQR: 18.00\n",
            "  Bounds: [-6.00, 66.00]\n",
            "  Outliers Count: 9\n",
            "  Sample Outliers: [71. 80. 76. 70. 71.]\n",
            "\n",
            "fare:\n",
            "  Quat1: 7.90, Quat3: 31.27, IQR: 23.38\n",
            "  Bounds: [-27.17, 66.34]\n",
            "  Outliers Count: 171\n",
            "  Sample Outliers: [211.3375 151.55   151.55   151.55   151.55  ]\n",
            "\n",
            "2.4 Covariance and Correlation  :\n",
            "\n",
            "age vs fare:\n",
            "  Covariance:  143.34\n",
            "  Correlation: 0.18\n",
            "  Interpretation: Positive weak relationship\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "STATISTICAL ANALYSIS\n",
        "CENTRAL TENDENCY AND DISPERSION\n",
        "'''\n",
        "\n",
        "print(\"\\n2.1 Measures of Central Tendency (Using python library Pandas):\")\n",
        "\n",
        "# For Numeric Attributes\n",
        "print(\"\\nNumeric Attributes Statistics:\")\n",
        "\n",
        "\n",
        "numeric_cols = ['age', 'fare', 'sibsp', 'parch']\n",
        "\n",
        "# using describe() to get : count, mean, std, min, 25%, 50%, 75%, max\n",
        "stats = titanic_data[numeric_cols].describe()\n",
        "\n",
        "for col in numeric_cols:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Mean:   {stats[col]['mean']:.2f}\")\n",
        "    print(f\"  Median: {stats[col]['50%']:.2f}\")\n",
        "    print(f\"  Mode:   {titanic_data[col].mode()[0]}\")\n",
        "\n",
        "# For Nominal Attributes - has mode only\n",
        "print(\"\\n\\nNominal Attributes - Mode (Using Pandas):\")\n",
        "\n",
        "\n",
        "for col in ['sex', 'embarked']:\n",
        "    print(f\"{col}: {titanic_data[col].mode()[0]}\")\n",
        "\n",
        "print(\"\\n2.2 Measures of Dispersion :\") \n",
        "\n",
        "\n",
        "for col in ['age', 'fare']:\n",
        "    data_col = titanic_data[col].dropna()\n",
        "\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Range:             {(data_col.max() - data_col.min()):.2f}\")\n",
        "    print(f\"  Variance:          {data_col.var():.2f}\")\n",
        "    print(f\"  Standard Dev:      {data_col.std():.2f}\")\n",
        "    print(f\"  Interquartile Rng: {(data_col.quantile(0.75) - data_col.quantile(0.25)):.2f}\")\n",
        " \n",
        "print(\"\\n2.3   Identifying Outliers using IQR Method :\")\n",
        "\n",
        "\n",
        "for col in ['age', 'fare']:\n",
        "    data_col = titanic_data[col].dropna()\n",
        "\n",
        "    Quat1 = data_col.quantile(0.25)\n",
        "    Quat3 = data_col.quantile(0.75)\n",
        "    IQR = Quat3 - Quat1\n",
        "\n",
        "    lower_bound = Quat1 - 1.5 * IQR\n",
        "    upper_bound = Quat3 + 1.5 * IQR\n",
        "\n",
        "    outliers = data_col[(data_col < lower_bound) | (data_col > upper_bound)]\n",
        "\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Quat1: {Quat1:.2f}, Quat3: {Quat3:.2f}, IQR: {IQR:.2f}\")\n",
        "    print(f\"  Bounds: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
        "    print(f\"  Outliers Count: {len(outliers)}\")\n",
        "\n",
        "    if len(outliers) > 0:\n",
        "        print(f\"  Sample Outliers: {outliers.head().values}\")\n",
        "\n",
        "print(\"\\n2.4 Covariance and Correlation  :\")\n",
        "\n",
        "\n",
        "age_fare = titanic_data[['age', 'fare']].dropna()\n",
        "\n",
        "covariance = age_fare.cov().loc['age', 'fare']\n",
        "correlation = age_fare.corr().loc['age', 'fare']\n",
        "\n",
        "print(f\"\\nage vs fare:\")\n",
        "print(f\"  Covariance:  {covariance:.2f}\")\n",
        "print(f\"  Correlation: {correlation:.2f}\")\n",
        "\n",
        "relationship = (\n",
        "    \"weak\" if abs(correlation) < 0.3\n",
        "    else \"moderate\" if abs(correlation) < 0.7\n",
        "    else \"strong\"\n",
        ")\n",
        "\n",
        "nature = \"Positive\" if correlation > 0 else \"Negative\"\n",
        "\n",
        "print(f\"  Interpretation: {nature} {relationship} relationship\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDZYIFAx5aA6"
      },
      "source": [
        "# **SECTION B**: STATISTICAL ANALYSIS, SIMILARITY AND DISTANCE MEASURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0flk2MY0WTj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Comparing: ['sex', 'cabin', 'embarked']\n",
            "Matches (m): 1/3\n",
            "Dissimilarity d(i,j): 0.667\n",
            "Similarity sim(i,j): 0.333\n"
          ]
        }
      ],
      "source": [
        "# Two passengers from the DataFrame\n",
        "passenger1 = titanic_data.iloc[0]\n",
        "passenger2 = titanic_data.iloc[1]\n",
        "\n",
        "# Proximity Measures for Nominal Attributes\n",
        "print(\"\\n3.2 Proximity Measures for NOMINAL Attributes:\")\n",
        "\n",
        "nominal_comparison = ['sex', 'cabin', 'embarked']\n",
        "\n",
        "# Converting to Pandas Series for vectorized comparison\n",
        "nom1 = passenger1[nominal_comparison].astype(str)\n",
        "nom2 = passenger2[nominal_comparison].astype(str)\n",
        "\n",
        "# Vectorized comparison using Pandas\n",
        "comparison_result = nom1.eq(nom2)\n",
        "\n",
        "# Number of matches using NumPy\n",
        "m = np.sum(comparison_result.values)\n",
        "p = len(nominal_comparison)\n",
        "\n",
        "# Dissimilarity & Similarity using NumPy\n",
        "dissimilarity = (p - m) / p\n",
        "similarity = 1 - dissimilarity\n",
        "\n",
        "print(f\"\\nComparing: {nominal_comparison}\")\n",
        "print(f\"Matches (m): {m}/{p}\")\n",
        "print(f\"Dissimilarity d(i,j): {dissimilarity:.3f}\")\n",
        "print(f\"Similarity sim(i,j): {similarity:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MoTHRIN0XJK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "3.3 Proximity Measures for BINARY Attributes:\n",
            "\n",
            "a) Symmetric Binary Dissimilarity (Hamming Distance):\n",
            "   Assumes 0 and 1 are equally important.\n",
            "   Dissimilarity: 0.000\n",
            "   Similarity:    1.000\n",
            "\n",
            "b) Asymmetric Binary Dissimilarity (Jaccard Coefficient):\n",
            "   Ignores negative matches (0-0).\n",
            "   Jaccard Similarity:    1.000\n",
            "   Asymmetric Dissimilarity: 0.000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\n3.3 Proximity Measures for BINARY Attributes:\")\n",
        "\n",
        "\n",
        "from scipy.spatial.distance import hamming\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "#binary attributes\n",
        "binary_cols = ['survived']\n",
        "\n",
        "# binary attributes values as integers\n",
        "b1 = passenger1[binary_cols].astype(int).values\n",
        "b2 = passenger2[binary_cols].astype(int).values\n",
        "\n",
        "\n",
        "# a) Symmetric Binary Dissimilarity (Hamming Distance)\n",
        "\n",
        "symmetric_dissim = hamming(b1, b2)\n",
        "symmetric_sim = 1 - symmetric_dissim\n",
        "\n",
        "print(\"\\na) Symmetric Binary Dissimilarity (Hamming Distance):\")\n",
        "print(f\"   Dissimilarity: {symmetric_dissim:.3f}\")\n",
        "print(f\"   Similarity:    {symmetric_sim:.3f}\")\n",
        "\n",
        "\n",
        "# b) Asymmetric Binary Dissimilarity (Jaccard Coefficient)\n",
        "\n",
        "try:\n",
        "    jaccard_sim = jaccard_score(b1, b2)\n",
        "except ValueError:\n",
        "    jaccard_sim = 0  # In case both values are 0 (undefined for Jaccard)\n",
        "\n",
        "asymmetric_dissim = 1 - jaccard_sim\n",
        "\n",
        "print(\"\\nb) Asymmetric Binary Dissimilarity (Jaccard Coefficient):\")\n",
        "print(\"   Ignores negative matches (0-0).\")\n",
        "print(f\"   Jaccard Similarity:    {jaccard_sim:.3f}\")\n",
        "print(f\"   Asymmetric Dissimilarity: {asymmetric_dissim:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "XAKEYLnU0hkk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " 3.4 Dissimilarity Measures for NUMERIC Attributes:\n",
            "\n",
            "Normalized Vectors:\n",
            "Passenger 1: [0.36114243 0.41250333]\n",
            "Passenger 2: [0.00939496 0.2958059 ]\n",
            "\n",
            "a) Euclidean Distance:\n",
            "   Distance: 0.3706\n",
            "\n",
            "b) Manhattan Distance:\n",
            "   Distance: 0.4684\n",
            "\n",
            "c) Minkowski Distance (h=3):\n",
            "   Distance: 0.3560\n",
            "\n",
            "d) Supremum (Chebyshev) Distance:\n",
            "   Distance: 0.3517\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n 3.4 Dissimilarity Measures for NUMERIC Attributes:\")\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.spatial.distance import euclidean, cityblock, minkowski, chebyshev\n",
        "\n",
        "# numeric columns to compare\n",
        "numeric_cols = ['age', 'fare']\n",
        "\n",
        "# Extracting values and handling missing values\n",
        "p1 = passenger1[numeric_cols].fillna(titanic_data[numeric_cols].mean()).values.reshape(1, -1)\n",
        "p2 = passenger2[numeric_cols].fillna(titanic_data[numeric_cols].mean()).values.reshape(1, -1)\n",
        "\n",
        "\n",
        "# Normalization using MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(titanic_data[numeric_cols])\n",
        "\n",
        "vec1 = scaler.transform(p1)[0]\n",
        "vec2 = scaler.transform(p2)[0]\n",
        "\n",
        "print(\"\\nNormalized Vectors:\")\n",
        "print(f\"Passenger 1: {vec1}\")\n",
        "print(f\"Passenger 2: {vec2}\")\n",
        "\n",
        "\n",
        "# a) Euclidean Distance\n",
        "\n",
        "euclidean_dist = euclidean(vec1, vec2)\n",
        "print(\"\\na) Euclidean Distance:\")\n",
        "print(f\"   Distance: {euclidean_dist:.4f}\")\n",
        "\n",
        "\n",
        "# b) Manhattan (City Block) Distance\n",
        "\n",
        "manhattan_dist = cityblock(vec1, vec2)\n",
        "print(\"\\nb) Manhattan Distance:\")\n",
        "print(f\"   Distance: {manhattan_dist:.4f}\")\n",
        "\n",
        "\n",
        "# c) Minkowski Distance (h=3)\n",
        "\n",
        "minkowski_dist = minkowski(vec1, vec2, p=3)\n",
        "print(f\"\\nc) Minkowski Distance (h=3):\")\n",
        "print(f\"   Distance: {minkowski_dist:.4f}\")\n",
        "\n",
        "\n",
        "# d) Supremum (Chebyshev) Distance\n",
        "\n",
        "chebyshev_dist = chebyshev(vec1, vec2)\n",
        "print(\"\\nd) Supremum (Chebyshev) Distance:\")\n",
        "print(f\"   Distance: {chebyshev_dist:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2htvFqJ01Vd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "Ths8ka320nks"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "3.5 Proximity Measures for ORDINAL Attributes:\n",
            "\n",
            "pclass comparison:\n",
            "Passenger 1: pclass=1 → normalized=0.000\n",
            "Passenger 2: pclass=1 → normalized=0.000\n",
            "Dissimilarity: 0.000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.spatial import distance\n",
        "\n",
        "\n",
        "print(\"\\n3.5 Proximity Measures for ORDINAL Attributes:\")\n",
        "\n",
        "\n",
        "# Extracting ordinal values (pclass)\n",
        "pclass1 = passenger1['pclass']\n",
        "pclass2 = passenger2['pclass']\n",
        "\n",
        "# array for scaling\n",
        "ordinal_data = np.array([[1], [2], [3]])\n",
        "\n",
        "# Normalizing using MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit(ordinal_data)\n",
        "\n",
        "z1 = scaler.transform([[pclass1]])[0][0]\n",
        "z2 = scaler.transform([[pclass2]])[0][0]\n",
        "\n",
        "print(f\"\\npclass comparison:\")\n",
        "print(f\"Passenger 1: pclass={pclass1} → normalized={z1:.3f}\")\n",
        "print(f\"Passenger 2: pclass={pclass2} → normalized={z2:.3f}\")\n",
        "\n",
        "# Ordinal dissimilarity using library (Cityblock / Absolute distance)\n",
        "ordinal_dissim = distance.cityblock([z1], [z2])\n",
        "\n",
        "print(f\"Dissimilarity: {ordinal_dissim:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "5WvpJMC008MO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "3.6 Dissimilarity for MIXED Attribute Types:\n",
            "\n",
            "Mixed-type dissimilarity between passengers: 0.2937\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Dissimilarity for Mixed Attribute Types\n",
        "\n",
        "print(\"\\n3.6 Dissimilarity for MIXED Attribute Types:\")\n",
        "\n",
        "\n",
        "# Calculate mixed dissimilarity\n",
        "def calc_mixed_dissimilarity(p1, p2, titanic_data):\n",
        "    total_dissim = 0\n",
        "    total_weight = 0\n",
        "\n",
        "    # Numeric: age, fare\n",
        "    for attr in ['age', 'fare']:\n",
        "        if pd.notna(p1[attr]) and pd.notna(p2[attr]):\n",
        "            min_val = titanic_data[attr].min()\n",
        "            max_val = titanic_data[attr].max()\n",
        "            d = abs(p1[attr] - p2[attr]) / (max_val - min_val) if max_val > min_val else 0\n",
        "            total_dissim += d\n",
        "            total_weight += 1\n",
        "\n",
        "    # Nominal: sex\n",
        "    if pd.notna(p1['sex']) and pd.notna(p2['sex']):\n",
        "        d = 0 if p1['sex'] == p2['sex'] else 1\n",
        "        total_dissim += d\n",
        "        total_weight += 1\n",
        "\n",
        "    # Ordinal: pclass\n",
        "    if pd.notna(p1['pclass']) and pd.notna(p2['pclass']):\n",
        "        M_f = 3\n",
        "        z1 = (p1['pclass'] - 1) / (M_f - 1)\n",
        "        z2 = (p2['pclass'] - 1) / (M_f - 1)\n",
        "        d = abs(z1 - z2)\n",
        "        total_dissim += d\n",
        "        total_weight += 1\n",
        "\n",
        "    # Binary: survived (asymmetric)\n",
        "    if p1['survived'] == 1 or p2['survived'] == 1:  # δ = 1 if at least one is 1\n",
        "        d = 0 if p1['survived'] == p2['survived'] else 1\n",
        "        total_dissim += d\n",
        "        total_weight += 1\n",
        "\n",
        "    return total_dissim / total_weight if total_weight > 0 else 0\n",
        "\n",
        "mixed_dissim = calc_mixed_dissimilarity(passenger1, passenger2, titanic_data)\n",
        "print(f\"\\nMixed-type dissimilarity between passengers: {mixed_dissim:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "CQrrKoWj1CBE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "3.7 Cosine Similarity (Library-Based):\n",
            "Using sklearn & scipy instead of manual computation\n",
            "\n",
            "Vectors:\n",
            "  x = [29.0, 211.34]\n",
            "  y = [0.9, 151.55]\n",
            "  Cosine Similarity: 0.9915\n",
            "\n",
            "Binary Cosine (Tanimoto Coefficient) – Library Based:\n",
            "Attributes: [survived, HasSibSp, HasParch]\n",
            "  X = [1 0 0], Y = [1 1 1]\n",
            "  Tanimoto Coefficient: 0.5774\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial import distance\n",
        "\n",
        "\n",
        "print(\"\\n3.7 Cosine Similarity (Library-Based):\")\n",
        "\n",
        "print(\"Using sklearn & scipy instead of manual computation\")\n",
        "\n",
        "\n",
        "#  1. COSINE SIMILARITY (NUMERIC)\n",
        "\n",
        "vec1_full = np.array([[p1_age, p1_fare]])\n",
        "vec2_full = np.array([[p2_age, p2_fare]])\n",
        "\n",
        "cosine_sim = cosine_similarity(vec1_full, vec2_full)[0][0]\n",
        "\n",
        "print(f\"\\nVectors:\")\n",
        "print(f\"  x = [{p1_age:.1f}, {p1_fare:.2f}]\")\n",
        "print(f\"  y = [{p2_age:.1f}, {p2_fare:.2f}]\")\n",
        "print(f\"  Cosine Similarity: {cosine_sim:.4f}\")\n",
        "\n",
        "\n",
        "# 2. BINARY COSINE (tanimoto distance)\n",
        "\n",
        "print(\"\\nBinary Cosine (Tanimoto Coefficient) – Library Based:\")\n",
        "print(\"Attributes: [survived, HasSibSp, HasParch]\")\n",
        "\n",
        "X = np.array([[passenger1['survived'],\n",
        "               1 if passenger1['sibsp'] > 0 else 0,\n",
        "               1 if passenger1['parch'] > 0 else 0]])\n",
        "\n",
        "Y = np.array([[passenger2['survived'],\n",
        "               1 if passenger2['sibsp'] > 0 else 0,\n",
        "               1 if passenger2['parch'] > 0 else 0]])\n",
        "\n",
        "# Tanimoto distance from scipy, then convert to similarity\n",
        "tanimoto_sim = 1 - distance.cosine(X[0], Y[0])\n",
        "\n",
        "print(f\"  X = {X[0]}, Y = {Y[0]}\")\n",
        "print(f\"  Tanimoto Coefficient: {tanimoto_sim:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqfLDowzBrUu",
        "outputId": "1b7f8593-bba4-4e97-e47e-a6e9fe559d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "3.8 KL Divergence \n",
            "Union symbols: ['a', 'b', 'c', 'd']\n",
            "\n",
            "Smoothed P:\n",
            "  a: 0.5996666666666667\n",
            "  b: 0.1996666666666667\n",
            "  c: 0.1996666666666667\n",
            "  d: 0.001\n",
            "\n",
            "Smoothed Q:\n",
            "  a: 0.5552222222222223\n",
            "  b: 0.33299999999999996\n",
            "  c: 0.001\n",
            "  d: 0.11077777777777777\n",
            "\n",
            "KL Divergence DKL(P||Q): 0.996906\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Library based KL-Divergence using entropy library\n",
        "\n",
        "from scipy.stats import entropy\n",
        "\n",
        "print(\"\\n3.8 KL Divergence \")\n",
        "\n",
        "# Given distributions\n",
        "P = {'a': 3/5, 'b': 1/5, 'c': 1/5}\n",
        "Q = {'a': 5/9, 'b': 3/9, 'd': 1/9}\n",
        "\n",
        "# Smoothing settings\n",
        "eps = 0.001\n",
        "eps3 = eps / 3\n",
        "\n",
        "# Union of symbols\n",
        "SU = sorted(list(set(P.keys()) | set(Q.keys())))  \n",
        "\n",
        "# Smoothed probability vectors\n",
        "Ps = []\n",
        "Qs = []\n",
        "\n",
        "for symbol in SU:\n",
        "    Ps.append(P[symbol] - eps3 if symbol in P else eps)\n",
        "    Qs.append(Q[symbol] - eps3 if symbol in Q else eps)\n",
        "\n",
        "Ps = np.array(Ps)\n",
        "Qs = np.array(Qs)\n",
        "\n",
        "\n",
        "KL = entropy(Ps, Qs)   \n",
        "\n",
        "print(\"Union symbols:\", SU)\n",
        "\n",
        "print(\"\\nSmoothed P:\")\n",
        "for s, v in zip(SU, Ps):\n",
        "    print(f\"  {s}: {v}\")\n",
        "\n",
        "print(\"\\nSmoothed Q:\")\n",
        "for s, v in zip(SU, Qs):\n",
        "    print(f\"  {s}: {v}\")\n",
        "\n",
        "print(f\"\\nKL Divergence DKL(P||Q): {KL:.6f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfQ2DslTGoTn"
      },
      "source": [
        "Note:\n",
        "\n",
        "*By smoothing the probability distributions of the Q and P symbols, the log(0) terms that would otherwise be undefined are removed for the instances of symbol c in Q, as well as symbol d in P.*\n",
        "\n",
        " *In addition, most of what we observe when determining the dominant contribution of symbol c to the overall log probability of all of the symbols in Q comes from the probability associated with symbol c, which is approximately 0.20 in P, and symbol c has virtually no associated probability (ε) in Q, meaning that using Q to encode data in P is very costly because Q gives very little weight (probability) (ε) to events that are considered to be likely (highly probable) by P.*\n",
        "\n",
        "\n",
        "*ε must be chosen small enough to avoid having a material impact on the overall distribution of the original data, but large enough to avoid any potential numerical issues (log0).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FF-a2BlEfot"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\"\\nTODO\\n\\nIn this lab as well as in class today we learned about the use\\nof many different types of formulas to perform various calculations.\\nHowever, the best way to do this is to use Python\\'s libraries instead of doing it manually.\\nPython is very powerful and has a lot of builtin libraries and external packages\\nthat can do these calculations very quickly and very accurately.\\n\\nRe do section B above and use Python libraries instead of manual calculation for these functions:\\n3. Central Tendency\\n4. Dispersion\\n5. Probability\\n6. KL Divergence\\n7. Distance Measures\\n'"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\"\n",
        "TODO\n",
        "\n",
        "In this lab as well as in class today we learned about the use\n",
        "of many different types of formulas to perform various calculations.\n",
        "However, the best way to do this is to use Python's libraries instead of doing it manually.\n",
        "Python is very powerful and has a lot of builtin libraries and external packages\n",
        "that can do these calculations very quickly and very accurately.\n",
        "\n",
        "Re do section B above and use Python libraries instead of manual calculation for these functions:\n",
        "3. Central Tendency\n",
        "4. Dispersion\n",
        "5. Probability\n",
        "6. KL Divergence\n",
        "7. Distance Measures\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8YGFlou5-6A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
